@inproceedings{kim-etal-2022-oh,
    title = "Oh My Mistake!: Toward Realistic Dialogue State Tracking including Turnback Utterances",
    author = "Kim, Takyoung  and
      Lee, Yukyung  and
      Yoon, Hoonsang  and
      Kang, Pilsung  and
      Bang, Junseong  and
      Kim, Misuk",
    editor = "Ou, Zhijian  and
      Feng, Junlan  and
      Li, Juanzi",
    booktitle = "Proceedings of the Towards Semi-Supervised and Reinforced Task-Oriented Dialog Systems (SereTOD)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, Beijing (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.seretod-1.1",
    doi = "10.18653/v1/2022.seretod-1.1",
    pages = "1--12",
    abstract = "The primary purpose of dialogue state tracking(DST), a critical component of an end-toend conversational system, is to build a model that responds well to real-world situations. Although we often change our minds from time to time during ordinary conversations, current benchmark datasets do not adequately reflect such occurrences and instead consist of over-simplified conversations, in which no one changes their mind during a conversation. As the main question inspiring the present study, {``}Are current benchmark datasets sufficiently diverse to handle casual conversations in which one changes their mind after a certain topic is over?{''} We found that the answer is {``}No{''} because DST models cannot refer to previous user preferences when template-based turnback utterances are injected into the dataset. Even in the the simplest mind-changing (turnback) scenario, the performance of DST models significantly degenerated. However, we found that this performance degeneration can be recovered when the turnback scenarios are explicitly designed in the training set, implying that the problem is not with the DST models but rather with the construction of the benchmark dataset.",
}